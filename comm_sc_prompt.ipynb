{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MifDuFeUd9ag"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3435882705.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 17\u001b[1;36m\u001b[0m\n\u001b[1;33m    file_path = 'C:\\Users\\rijaa\\Downloads\\firstpart_after_ui (3)\\firstpart_after_ui\\firstpart\\trainn.csv'\u001b[0m\n\u001b[1;37m                                                                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Part 1: Model Training\n",
    "file_path = 'C:\\Users\\rijaa\\Downloads\\firstpart_after_ui (3)\\firstpart_after_ui\\firstpart\\trainn.csv'\n",
    "try:\n",
    "    data = pd.read_csv(file_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "data = data.dropna(subset=['Post', 'Lead'])\n",
    "data['Lead'] = data['Lead'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_features=5000)\n",
    "X = vectorizer.fit_transform(data['Post'])\n",
    "y = data['Lead']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'saga'], 'max_iter': [1000, 2000]}\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Part 2: Facebook Post Extraction\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# Login to Facebook\n",
    "url = 'http://www.facebook.com'\n",
    "driver.get(url)\n",
    "username = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='email']\")))\n",
    "password = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='pass']\")))\n",
    "\n",
    "username.clear()\n",
    "username.send_keys(\"aroobaminhas14@gmail.com\")\n",
    "password.clear()\n",
    "password.send_keys(\"beautyinsights\")\n",
    "wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\"))).click()\n",
    "time.sleep(5)\n",
    "\n",
    "# Navigate to the group/page\n",
    "page_url = 'https://www.facebook.com/groups/2295020414190663'\n",
    "driver.get(page_url)\n",
    "time.sleep(5)\n",
    "\n",
    "max_posts = 10\n",
    "all_posts = []\n",
    "scraped_posts = set()\n",
    "scroll_attempts = 0\n",
    "max_scroll_attempts = 5\n",
    "scraped_posts_count = 0\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while scraped_posts_count < max_posts and scroll_attempts < max_scroll_attempts:\n",
    "    try:\n",
    "        posts = driver.find_elements(By.XPATH, \"//*[contains(@data-ad-comet-preview, 'message') and contains(@data-ad-preview, 'message')]\")\n",
    "        for post in posts:\n",
    "            try:\n",
    "                try:\n",
    "                    see_more_button = post.find_element(By.XPATH, \".//div[contains(text(), 'See more')]\")\n",
    "                    driver.execute_script(\"arguments[0].click();\", see_more_button)\n",
    "                    time.sleep(1)\n",
    "                except NoSuchElementException:\n",
    "                    pass\n",
    "\n",
    "                post_text_parts = post.find_elements(By.XPATH, \".//div[@style='text-align: start;']\")\n",
    "                post_text = \" \".join([part.text for part in post_text_parts if part.text])\n",
    "                post_id = post.get_attribute(\"id\") or None\n",
    "\n",
    "                if post_id and post_id not in scraped_posts:\n",
    "                    scraped_posts.add(post_id)\n",
    "                    if post_text:\n",
    "                        all_posts.append({'Post': post_text, 'Post ID': post_id})\n",
    "                        scraped_posts_count += 1\n",
    "                    if scraped_posts_count >= max_posts:\n",
    "                        break\n",
    "            except StaleElementReferenceException:\n",
    "                continue\n",
    "\n",
    "        if scraped_posts_count >= max_posts:\n",
    "            break\n",
    "\n",
    "        driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "        time.sleep(3)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            scroll_attempts += 1\n",
    "        else:\n",
    "            scroll_attempts = 0\n",
    "        last_height = new_height\n",
    "\n",
    "    except StaleElementReferenceException:\n",
    "        continue\n",
    "\n",
    "df_posts = pd.DataFrame(all_posts)\n",
    "\n",
    "# Part 3: Predict Lead/Non-Lead and Save Results\n",
    "df_posts['Lead'] = best_model.predict(vectorizer.transform(df_posts['Post']))\n",
    "df_posts.to_csv('classified_posts2.csv', index=False)\n",
    "\n",
    "print(f\"Classified posts have been saved to classified_posts2.csv. Total posts scraped: {scraped_posts_count}.\")\n",
    "\n",
    "# Part 4: Comment on Lead Posts\n",
    "def comment_on_lead_posts(driver, posts_df, comment_text):\n",
    "    lead_posts = posts_df[posts_df['Lead'] == 1]\n",
    "\n",
    "    for _, post in lead_posts.iterrows():\n",
    "        post_id = post['Post ID']\n",
    "\n",
    "        try:\n",
    "            # Locate comment button\n",
    "            comment_button = driver.find_element(By.XPATH, f\"//span[@data-ad-rendering-role='comment_button']\")\n",
    "            driver.execute_script(\"arguments[0].click();\", comment_button)\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Locate text box\n",
    "            text_box = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//div[@aria-label='Write an answerâ€¦' and @contenteditable='true']\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", text_box)\n",
    "            text_box.send_keys(comment_text + Keys.RETURN)\n",
    "            time.sleep(2)\n",
    "\n",
    "            print(f\"Commented on post ID: {post_id}\")\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(f\"Could not find the comment button or box for post ID: {post_id}. Skipping...\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while commenting on post ID: {post_id}: {e}\")\n",
    "\n",
    "comment_text = \"For getting this service, please visit our store.\"\n",
    "comment_on_lead_posts(driver, df_posts, comment_text)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnH2ydHkeCd-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
