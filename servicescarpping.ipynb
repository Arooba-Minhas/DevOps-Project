{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ali code\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# Navigate to Facebook login page\n",
    "url = 'http://www.facebook.com'\n",
    "driver.get(url)\n",
    "\n",
    "# Target username and password fields\n",
    "username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='email']\")))\n",
    "password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='pass']\")))\n",
    "\n",
    "# Enter credentials\n",
    "username.clear()\n",
    "username.send_keys(\"aroobaminhas14@gmail.com\")\n",
    "password.clear()\n",
    "password.send_keys(\"beautyinsights\") \n",
    "\n",
    "# Click login button\n",
    "button = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\"))).click()\n",
    "time.sleep(5)  \n",
    "\n",
    "page_url = 'https://www.facebook.com/groups/superwomenofpakistan/'\n",
    "driver.get(page_url)\n",
    "time.sleep(5)  \n",
    "\n",
    "all_posts = []\n",
    "\n",
    "for _ in range(50):\n",
    "    try:\n",
    "        posts = driver.find_elements(By.XPATH, \"//*[contains(@data-ad-comet-preview, 'message') and contains(@data-ad-preview, 'message')]\")\n",
    "\n",
    "        for post in posts:\n",
    "            try:\n",
    "                # Check and click the \"See more\" button if it exists\n",
    "                try:\n",
    "                    see_more_button = post.find_element(By.XPATH, \".//div[contains(text(), 'See more')]\")\n",
    "                    driver.execute_script(\"arguments[0].click();\", see_more_button)\n",
    "                    time.sleep(1) \n",
    "                except NoSuchElementException:\n",
    "                    pass\n",
    "\n",
    "                # Collect all inner div text elements within each post\n",
    "                post_text_parts = post.find_elements(By.XPATH, \".//div[@style='text-align: start;']\")\n",
    "                post_text = \" \".join([part.text for part in post_text_parts if part.text]) \n",
    "\n",
    "                # Extract the post ID\n",
    "                try:\n",
    "                    post_id = post.get_attribute(\"id\")  # Directly access the 'id' attribute\n",
    "                except NoSuchElementException:\n",
    "                    post_id = None\n",
    "\n",
    "                if post_text:\n",
    "                    all_posts.append({'Post': post_text, 'Post ID': post_id})\n",
    "            except StaleElementReferenceException:\n",
    "                continue\n",
    "    \n",
    "    except StaleElementReferenceException:\n",
    "        continue\n",
    "\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(3) \n",
    "\n",
    "df_posts = pd.DataFrame(all_posts)\n",
    "df_posts.to_csv('facebook_page_posts_with_ids.csv', index=False)\n",
    "print(\"Posts and Post IDs have been saved to facebook_page_posts_with_ids.csv\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Extration parsing into table form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to parsed_services.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "\n",
    "# Path to the extracted text file\n",
    "service_text_file = \"extracted_text5.txt\"\n",
    "\n",
    "def parse_services(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    services = re.split(r'--- Text from .* ---', content)\n",
    "    parsed_services = []\n",
    "\n",
    "    for service in services:\n",
    "        if service.strip():\n",
    "            lines = service.strip().split(\"\\n\")\n",
    "            service_provider = lines[0] if lines else \"Unknown Service Provider\"\n",
    "\n",
    "            details = \" \".join(lines[1:])\n",
    "            # Extract deal number\n",
    "            deal_match = re.search(r'DEAL\\s+\\d+', details, re.IGNORECASE)\n",
    "            deal = deal_match.group() if deal_match else \"Unknown Deal\"\n",
    "            \n",
    "            # Extract all prices\n",
    "            price_matches = re.findall(r'Rs\\.\\s*\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?/-', details)\n",
    "            price = \", \".join(price_matches) if price_matches else \"Price not specified\"\n",
    "            \n",
    "            # Extract services offered (all text before the first price occurrence)\n",
    "            price_index = details.find(price_matches[0]) if price_matches else len(details)\n",
    "            services_offered = details[:price_index].strip()\n",
    "\n",
    "            parsed_services.append({\n",
    "                \"Service_Provider\": service_provider.strip(),\n",
    "                \"Deal\": deal.strip(),\n",
    "                \"Services_Offered\": services_offered.strip(),\n",
    "                \"Price\": price.strip(),\n",
    "                \"Details\": details.strip()\n",
    "            })\n",
    "\n",
    "    return parsed_services\n",
    "\n",
    "services_data = parse_services(service_text_file)\n",
    "\n",
    "csv_file = \"parsed_services.csv\"\n",
    "csv_columns = [\"Service_Provider\", \"Deal\", \"Services_Offered\", \"Price\", \"Details\"]\n",
    "\n",
    "try:\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(services_data)\n",
    "    print(f\"Data successfully written to {csv_file}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error writing to CSV file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the entire DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Service_Provider</th>\n",
       "      <th>Deal</th>\n",
       "      <th>Services_Offered</th>\n",
       "      <th>Price</th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIMS BEAUTY SALON</td>\n",
       "      <td>DEAL 39</td>\n",
       "      <td>DEAL 39 HAIR DEAL Base Color Highlights Lowlig...</td>\n",
       "      <td>Rs.10,000/-, Rs.12,000/-</td>\n",
       "      <td>DEAL 39 HAIR DEAL Base Color Highlights Lowlig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NSMVA SALON</td>\n",
       "      <td>DEAL 41</td>\n",
       "      <td>DEAL 41 HYDRAFACIAL Manicure Pedicure Eyebrows...</td>\n",
       "      <td>Rs. 4,999/-</td>\n",
       "      <td>DEAL 41 HYDRAFACIAL Manicure Pedicure Eyebrows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIMS BEAUTY SALON</td>\n",
       "      <td>DEAL 38</td>\n",
       "      <td>DEAL 38 HAIR DEAL Fashion Dye Hair Cut Blow Dr...</td>\n",
       "      <td>Rs. 6,000/-</td>\n",
       "      <td>DEAL 38 HAIR DEAL Fashion Dye Hair Cut Blow Dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SARA SALON</td>\n",
       "      <td>DEAL 37</td>\n",
       "      <td>DEAL 37 FULL BODY MASSAGE Head Massage Deep Co...</td>\n",
       "      <td>Rs. 1,499/-</td>\n",
       "      <td>DEAL 37 FULL BODY MASSAGE Head Massage Deep Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NIMS BEAUTY SALON</td>\n",
       "      <td>DEAL 36</td>\n",
       "      <td>DEAL 36 SKIN DEAL Teen Age Cleansing Whitening...</td>\n",
       "      <td>Rs. 4,500/-</td>\n",
       "      <td>DEAL 36 SKIN DEAL Teen Age Cleansing Whitening...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Service_Provider     Deal  \\\n",
       "0  AIMS BEAUTY SALON  DEAL 39   \n",
       "1        NSMVA SALON  DEAL 41   \n",
       "2  AIMS BEAUTY SALON  DEAL 38   \n",
       "3         SARA SALON  DEAL 37   \n",
       "4  NIMS BEAUTY SALON  DEAL 36   \n",
       "\n",
       "                                    Services_Offered  \\\n",
       "0  DEAL 39 HAIR DEAL Base Color Highlights Lowlig...   \n",
       "1  DEAL 41 HYDRAFACIAL Manicure Pedicure Eyebrows...   \n",
       "2  DEAL 38 HAIR DEAL Fashion Dye Hair Cut Blow Dr...   \n",
       "3  DEAL 37 FULL BODY MASSAGE Head Massage Deep Co...   \n",
       "4  DEAL 36 SKIN DEAL Teen Age Cleansing Whitening...   \n",
       "\n",
       "                      Price                                            Details  \n",
       "0  Rs.10,000/-, Rs.12,000/-  DEAL 39 HAIR DEAL Base Color Highlights Lowlig...  \n",
       "1               Rs. 4,999/-  DEAL 41 HYDRAFACIAL Manicure Pedicure Eyebrows...  \n",
       "2               Rs. 6,000/-  DEAL 38 HAIR DEAL Fashion Dye Hair Cut Blow Dr...  \n",
       "3               Rs. 1,499/-  DEAL 37 FULL BODY MASSAGE Head Massage Deep Co...  \n",
       "4               Rs. 4,500/-  DEAL 36 SKIN DEAL Teen Age Cleansing Whitening...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'parsed_services.csv' \n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Displaying the entire DataFrame:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre processing the Facebook Post data and matching it with our service details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed posts saved to: processed_facebook_posts.csv\n",
      "Leads file saved to: leads.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Muham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Muham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "services_df = pd.read_csv(\"parsed_services.csv\")\n",
    "posts_df = pd.read_csv(\"facebook_page_posts_with_ids.csv\")\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special characters, numbers, and convert to lowercase\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", str(text))  # Keep only letters and spaces\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "posts_df[\"Cleaned_Post\"] = posts_df[\"Post\"].apply(clean_text)\n",
    "\n",
    "# Step 2: Match posts with keywords, keeping only the first match\n",
    "leads = []\n",
    "\n",
    "# Extract keywords from 'Services_Offered' column\n",
    "keywords = services_df[\"Services_Offered\"].str.lower().str.split().explode().unique()\n",
    "\n",
    "# Match posts with keywords, stopping after the first match\n",
    "for index, row in posts_df.iterrows():\n",
    "    post = row[\"Cleaned_Post\"]  \n",
    "    post_id = row[\"Post ID\"]   \n",
    "    for _, service_row in services_df.iterrows():\n",
    "        if any(keyword in post for keyword in keywords):  # Check for keyword match\n",
    "            leads.append({\n",
    "                \"Post\": row[\"Post\"],\n",
    "                \"Post ID\": post_id,\n",
    "                \"Service_Provider\": service_row[\"Service_Provider\"],\n",
    "                \"Deal\": service_row[\"Deal\"]\n",
    "            })\n",
    "            break  # Stop further matching for this post\n",
    "\n",
    "# Step 3: Save results to leads file\n",
    "leads_df = pd.DataFrame(leads)\n",
    "leads_file_path = \"leads.csv\"\n",
    "leads_df.to_csv(leads_file_path, index=False)\n",
    "\n",
    "# Step 4: Save processed posts to a new file\n",
    "processed_file_path = \"processed_facebook_posts.csv\"\n",
    "posts_df.to_csv(processed_file_path, index=False)\n",
    "\n",
    "print(f\"Processed posts saved to: {processed_file_path}\")\n",
    "print(f\"Leads file saved to: {leads_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the entire DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post</th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Service_Provider</th>\n",
       "      <th>Deal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Presenting our hot seller ludo  / chess and co...</td>\n",
       "      <td>:r89:</td>\n",
       "      <td>AIMS BEAUTY SALON</td>\n",
       "      <td>DEAL 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Post - 1  Frosted Sunlight  https://chat.whats...</td>\n",
       "      <td>:ra6:</td>\n",
       "      <td>AIMS BEAUTY SALON</td>\n",
       "      <td>DEAL 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I need to buy nighty and undergarments for my ...</td>\n",
       "      <td>:rb2:</td>\n",
       "      <td>AIMS BEAUTY SALON</td>\n",
       "      <td>DEAL 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thanks a ton everyone for your input. I am now...</td>\n",
       "      <td>:rc0:</td>\n",
       "      <td>AIMS BEAUTY SALON</td>\n",
       "      <td>DEAL 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just regretting my decision  Social media p hy...</td>\n",
       "      <td>:re4:</td>\n",
       "      <td>AIMS BEAUTY SALON</td>\n",
       "      <td>DEAL 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Assalamualaikum all.. This is Mahwish Adil own...</td>\n",
       "      <td>:r84a:</td>\n",
       "      <td>AIMS BEAUTY SALON</td>\n",
       "      <td>DEAL 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Post#2  Launching My New Handmade Home decor  ...</td>\n",
       "      <td>:r857:</td>\n",
       "      <td>AIMS BEAUTY SALON</td>\n",
       "      <td>DEAL 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Mujhe is tarhan k frames bnwane henn in differ...</td>\n",
       "      <td>:r865:</td>\n",
       "      <td>AIMS BEAUTY SALON</td>\n",
       "      <td>DEAL 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Has anybody selling these kind of namaz chadars?</td>\n",
       "      <td>:r883:</td>\n",
       "      <td>AIMS BEAUTY SALON</td>\n",
       "      <td>DEAL 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>What is the best way to earn dollars online?  ...</td>\n",
       "      <td>:r88v:</td>\n",
       "      <td>AIMS BEAUTY SALON</td>\n",
       "      <td>DEAL 39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Post Post ID  \\\n",
       "0    Presenting our hot seller ludo  / chess and co...   :r89:   \n",
       "1    Post - 1  Frosted Sunlight  https://chat.whats...   :ra6:   \n",
       "2    I need to buy nighty and undergarments for my ...   :rb2:   \n",
       "3    Thanks a ton everyone for your input. I am now...   :rc0:   \n",
       "4    Just regretting my decision  Social media p hy...   :re4:   \n",
       "..                                                 ...     ...   \n",
       "106  Assalamualaikum all.. This is Mahwish Adil own...  :r84a:   \n",
       "107  Post#2  Launching My New Handmade Home decor  ...  :r857:   \n",
       "108  Mujhe is tarhan k frames bnwane henn in differ...  :r865:   \n",
       "109   Has anybody selling these kind of namaz chadars?  :r883:   \n",
       "110  What is the best way to earn dollars online?  ...  :r88v:   \n",
       "\n",
       "      Service_Provider     Deal  \n",
       "0    AIMS BEAUTY SALON  DEAL 39  \n",
       "1    AIMS BEAUTY SALON  DEAL 39  \n",
       "2    AIMS BEAUTY SALON  DEAL 39  \n",
       "3    AIMS BEAUTY SALON  DEAL 39  \n",
       "4    AIMS BEAUTY SALON  DEAL 39  \n",
       "..                 ...      ...  \n",
       "106  AIMS BEAUTY SALON  DEAL 39  \n",
       "107  AIMS BEAUTY SALON  DEAL 39  \n",
       "108  AIMS BEAUTY SALON  DEAL 39  \n",
       "109  AIMS BEAUTY SALON  DEAL 39  \n",
       "110  AIMS BEAUTY SALON  DEAL 39  \n",
       "\n",
       "[111 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'leads.csv' \n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Displaying the entire DataFrame:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lead and Non Lead: Leads saved to refined_leads_with_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined leads saved to refined_leads_with_ids.csv\n",
      "Potential review comments saved to potential_review_comments.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load the datasets\n",
    "services_file_path = 'parsed_services.csv'  # Replace with your actual file path\n",
    "comments_file_path = 'facebook_page_posts_with_ids.csv'  # Replace with your actual file path\n",
    "\n",
    "services_data = pd.read_csv(services_file_path)\n",
    "comments_data = pd.read_csv(comments_file_path)\n",
    "\n",
    "# Step 1: Extract Keywords from Services Data\n",
    "# Combine all text from \"Services_Offered\" and \"Details\"\n",
    "services_text = (\n",
    "    services_data['Services_Offered'].astype(str).tolist()\n",
    "    + services_data['Details'].astype(str).tolist()\n",
    ")\n",
    "\n",
    "# Extract unique keywords\n",
    "services_keywords = set()\n",
    "for text in services_text:\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())  # Extract words ignoring punctuation\n",
    "    services_keywords.update(words)\n",
    "\n",
    "# Filter keywords: Remove generic/stopwords and short words\n",
    "stopwords = set(['000', '1', '2', '10', 'deal', 'price', 'details', 'the', 'of', 'and', 'for', 'on', 'a', 'in', 'is'])\n",
    "refined_keywords = [word for word in services_keywords if word not in stopwords and len(word) > 2]\n",
    "\n",
    "# Step 2: Preprocess Comments Data\n",
    "def preprocess_text(text):\n",
    "    return re.sub(r'http\\S+|www.\\S+|[^\\w\\s]', '', text.lower())  # Remove links, special chars, and lowercase\n",
    "\n",
    "comments_data['Cleaned_Post'] = comments_data['Post'].astype(str).apply(preprocess_text)\n",
    "\n",
    "# Step 3: Identify Leads\n",
    "def identify_leads(post, keywords):\n",
    "    # Check if any of the keywords appear in the cleaned post\n",
    "    return any(keyword in post for keyword in keywords)\n",
    "\n",
    "comments_data['Lead'] = comments_data['Cleaned_Post'].apply(lambda post: 'Lead' if identify_leads(post, refined_keywords) else 'Non-Lead')\n",
    "\n",
    "# Step 4: NLP Enhancement (Optional): Using Bag-of-Words Matching for Improved Intent Detection\n",
    "vectorizer = CountVectorizer(vocabulary=refined_keywords)\n",
    "keywords_matrix = vectorizer.fit_transform(comments_data['Cleaned_Post'])\n",
    "comments_data['Lead_Score'] = keywords_matrix.sum(axis=1)  # Score based on keyword frequency\n",
    "\n",
    "# Step 5: Reclassify Comments with Lead_Score = 0\n",
    "comments_data['Lead'] = comments_data.apply(\n",
    "    lambda row: 'Non-Lead' if row['Lead_Score'] == 0 else row['Lead'], axis=1\n",
    ")\n",
    "\n",
    "# Step 6: Apply Threshold for Lead_Score\n",
    "confidence_threshold = 2  # Minimum score for confident classification\n",
    "comments_data['Lead'] = comments_data.apply(\n",
    "    lambda row: 'Non-Lead' if row['Lead_Score'] < confidence_threshold else row['Lead'], axis=1\n",
    ")\n",
    "\n",
    "# Step 7: Filter Leads and Export Results\n",
    "leads_data = comments_data[comments_data['Lead'] == 'Lead']\n",
    "output_leads_path = 'refined_leads_with_ids.csv'\n",
    "leads_data[['Post ID', 'Post', 'Cleaned_Post', 'Lead', 'Lead_Score']].to_csv(output_leads_path, index=False)\n",
    "\n",
    "# Step 8: Export Non-Leads and Potential Review Comments\n",
    "review_data = comments_data[(comments_data['Lead'] == 'Non-Lead') & (comments_data['Lead_Score'] > 0)]\n",
    "review_output_path = 'potential_review_comments.csv'\n",
    "review_data[['Post ID', 'Post', 'Cleaned_Post', 'Lead', 'Lead_Score']].to_csv(review_output_path, index=False)\n",
    "\n",
    "# Output Messages\n",
    "print(f\"Refined leads saved to {output_leads_path}\")\n",
    "print(f\"Potential review comments saved to {review_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the entire DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Post</th>\n",
       "      <th>Cleaned_Post</th>\n",
       "      <th>Lead</th>\n",
       "      <th>Lead_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:r3k:</td>\n",
       "      <td>Looking for interne for the following position...</td>\n",
       "      <td>looking for interne for the following position...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:r9j:</td>\n",
       "      <td>Clearance SALE Khaddar Stitched 2pc Shirt and...</td>\n",
       "      <td>clearance sale khaddar stitched 2pc shirt and...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>:rci:</td>\n",
       "      <td>Hi Mommies! We are hiring at Kumon DHA Phase 8...</td>\n",
       "      <td>hi mommies we are hiring at kumon dha phase 8 ...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:rf1:</td>\n",
       "      <td>I want 3 to 4 family (parents and babyboy) pic...</td>\n",
       "      <td>i want 3 to 4 family parents and babyboy pictu...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>:ri7:</td>\n",
       "      <td>I have a functions coming up and I want to go ...</td>\n",
       "      <td>i have a functions coming up and i want to go ...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>:r7m9:</td>\n",
       "      <td>order now at Seemalite  instagram.com/seemalit...</td>\n",
       "      <td>order now at seemalite  instagramcomseemalite2...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>:r7rr:</td>\n",
       "      <td>Unlock Your Earning Potential Through Social M...</td>\n",
       "      <td>unlock your earning potential through social m...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>:r851:</td>\n",
       "      <td>Assalamu Alaikum. I am looking for a female ph...</td>\n",
       "      <td>assalamu alaikum i am looking for a female pho...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>:r88b:</td>\n",
       "      <td>Season end sale with massive discouts on our p...</td>\n",
       "      <td>season end sale with massive discouts on our p...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>:r8a1:</td>\n",
       "      <td>PREMIUM DRY FRUIT, SEEDS &amp; FRESH DRIED FRUITS ...</td>\n",
       "      <td>premium dry fruit seeds  fresh dried fruits fr...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Post ID                                               Post  \\\n",
       "0    :r3k:  Looking for interne for the following position...   \n",
       "1    :r9j:   Clearance SALE Khaddar Stitched 2pc Shirt and...   \n",
       "2    :rci:  Hi Mommies! We are hiring at Kumon DHA Phase 8...   \n",
       "3    :rf1:  I want 3 to 4 family (parents and babyboy) pic...   \n",
       "4    :ri7:  I have a functions coming up and I want to go ...   \n",
       "..     ...                                                ...   \n",
       "78  :r7m9:  order now at Seemalite  instagram.com/seemalit...   \n",
       "79  :r7rr:  Unlock Your Earning Potential Through Social M...   \n",
       "80  :r851:  Assalamu Alaikum. I am looking for a female ph...   \n",
       "81  :r88b:  Season end sale with massive discouts on our p...   \n",
       "82  :r8a1:  PREMIUM DRY FRUIT, SEEDS & FRESH DRIED FRUITS ...   \n",
       "\n",
       "                                         Cleaned_Post  Lead  Lead_Score  \n",
       "0   looking for interne for the following position...  Lead           3  \n",
       "1    clearance sale khaddar stitched 2pc shirt and...  Lead           2  \n",
       "2   hi mommies we are hiring at kumon dha phase 8 ...  Lead           3  \n",
       "3   i want 3 to 4 family parents and babyboy pictu...  Lead           4  \n",
       "4   i have a functions coming up and i want to go ...  Lead           6  \n",
       "..                                                ...   ...         ...  \n",
       "78  order now at seemalite  instagramcomseemalite2...  Lead           4  \n",
       "79  unlock your earning potential through social m...  Lead           7  \n",
       "80  assalamu alaikum i am looking for a female pho...  Lead           2  \n",
       "81  season end sale with massive discouts on our p...  Lead           6  \n",
       "82  premium dry fruit seeds  fresh dried fruits fr...  Lead           4  \n",
       "\n",
       "[83 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'refined_leads_with_ids.csv' \n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Displaying the entire DataFrame:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# # Load the leads CSV\n",
    "# leads_df = pd.read_csv(\"refined_leads_with_ids.csv\")\n",
    "# leads_dict = dict(zip(leads_df['Post ID'], leads_df['Post']))\n",
    "\n",
    "# # Initialize WebDriver\n",
    "# driver = webdriver.Chrome()\n",
    "# driver.maximize_window()\n",
    "# wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# # Navigate to Facebook login page\n",
    "# url = 'http://www.facebook.com'\n",
    "# driver.get(url)\n",
    "\n",
    "# # Target username and password fields\n",
    "# username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='email']\")))\n",
    "# password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='pass']\")))\n",
    "\n",
    "# # Enter credentials\n",
    "# username.clear()\n",
    "# username.send_keys(\"aroobaminhas14@gmail.com\")\n",
    "# password.clear()\n",
    "# password.send_keys(\"beautyinsights\")\n",
    "\n",
    "# # Click login button\n",
    "# button = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\"))).click()\n",
    "# time.sleep(5)\n",
    "\n",
    "# # Navigate to the group/page URL\n",
    "# page_url = 'https://www.facebook.com/groups/superwomenofpakistan/'\n",
    "# driver.get(page_url)\n",
    "# time.sleep(5)\n",
    "\n",
    "# # Extract posts\n",
    "# all_posts = []\n",
    "\n",
    "# for _ in range(20):  # Adjust scroll count as needed\n",
    "#     try:\n",
    "#         posts = driver.find_elements(By.XPATH, \"//*[contains(@data-ad-comet-preview, 'message') and contains(@data-ad-preview, 'message')]\")\n",
    "\n",
    "#         for post in posts:\n",
    "#             try:\n",
    "#                 # Check and click \"See more\" if present\n",
    "#                 try:\n",
    "#                     see_more_button = post.find_element(By.XPATH, \".//div[contains(text(), 'See more')]\")\n",
    "#                     driver.execute_script(\"arguments[0].click();\", see_more_button)\n",
    "#                     time.sleep(1)\n",
    "#                 except NoSuchElementException:\n",
    "#                     pass\n",
    "\n",
    "#                 # Collect post text and ID\n",
    "#                 post_text_parts = post.find_elements(By.XPATH, \".//div[@style='text-align: start;']\")\n",
    "#                 post_text = \" \".join([part.text for part in post_text_parts if part.text])\n",
    "#                 post_id = post.get_attribute(\"id\")\n",
    "\n",
    "#                 if post_text and post_id:\n",
    "#                     all_posts.append({'Post': post_text, 'Post ID': post_id})\n",
    "\n",
    "#                     # Match post ID with leads data\n",
    "#                     if post_id in leads_dict:\n",
    "#                         comment_text = f\"Hi, we noticed your post: '{leads_dict[post_id]}'. We’d love to assist you with our services!\"\n",
    "\n",
    "#                         # Scroll to the post\n",
    "#                         driver.execute_script(\"arguments[0].scrollIntoView(true);\", post)\n",
    "#                         time.sleep(1)\n",
    "\n",
    "#                         try:\n",
    "#                             # Locate and click the \"Comment\" button\n",
    "#                             comment_button = post.find_element(By.XPATH, \".//span[@data-ad-rendering-role='comment_button']\")\n",
    "#                             driver.execute_script(\"arguments[0].click();\", comment_button)\n",
    "#                             time.sleep(2)\n",
    "\n",
    "#                             # Locate the comment box after clicking the \"Comment\" button\n",
    "#                             comment_box = post.find_element(By.XPATH, \".//div[@aria-label='Write an answer…' and @contenteditable='true']\")\n",
    "#                             comment_box.click()  # Ensure focus on the text box\n",
    "#                             time.sleep(1)\n",
    "#                             comment_box.send_keys(comment_text)\n",
    "#                             comment_box.send_keys(\"\\n\")  # Press Enter to post the comment\n",
    "#                             print(f\"Commented on post {post_id}: {comment_text}\")\n",
    "\n",
    "#                         except NoSuchElementException:\n",
    "#                             print(f\"Failed to comment on post {post_id}: Comment button or text box not found\")\n",
    "\n",
    "#             except StaleElementReferenceException:\n",
    "#                 continue\n",
    "\n",
    "#     except StaleElementReferenceException:\n",
    "#         continue\n",
    "\n",
    "#     # Scroll to load more posts\n",
    "#     driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#     time.sleep(3)\n",
    "\n",
    "# # Save posts to a CSV for reference\n",
    "# df_posts = pd.DataFrame(all_posts)\n",
    "# df_posts.to_csv('reference.csv', index=False)\n",
    "# print(\"Posts and Post IDs have been saved to facebook_page_posts_with_ids.csv\")\n",
    "\n",
    "# # Quit the driver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
